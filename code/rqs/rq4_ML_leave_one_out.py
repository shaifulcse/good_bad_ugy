# -*- coding: utf-8 -*-
"""good_bad_ugly.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FdkubISuG8CL5mrmCxYdYX0ZqsXMPYgF
"""
import os

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from imblearn.over_sampling import RandomOverSampler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from util import utility

SRC_PATH = utility.BASE_PATH + "/data/ML/all/"
DEST_PATH = utility.BASE_PATH + "/data/ML/train-test/"

selected_features = ["SLOCStandard",
                     "CommentCodeRation",
                     "Readability",
                     "SimpleReadability",
                     "NVAR",
                     "NCOMP",
                     "McCabe",
                     "IndentSTD",
                     "MaximumBlockDepth",
                     "totalFanOut",
                     "Length",
                     "MaintainabilityIndex",
                     "isPublic",
                     "isStatic",
                     "isGetterSetter",
                     "Parameters",
                     "LocalVariables"
                     ]


def load_data(train_file, test_file):
    train_data = pd.read_csv(train_file, sep='\t')
    test_data = pd.read_csv(test_file, sep='\t')
    return train_data, test_data


def clean_data(data):
    data = data[data.Type != 'noise']
    data = data[data.Type != 'bad']
    X = data[selected_features]
    Y = data["Type"]
    return X, Y


def oversampling(X, Y):
    ros = RandomOverSampler()
    X, Y = ros.fit_resample(X, Y)
    return X, Y


def report_results(type_data, algorithm, actual_y, pred_y, test_project):
    print("Results for ", algorithm)
    print("For", type_data)
    accuracy = accuracy_score(actual_y,
                              pred_y)  # https://medium.com/@maxgrossman10/accuracy-recall-precision-f1-score-with-python-4f2ee97e0d6
    print("Accuracy: ", accuracy)

    precision = precision_score(actual_y, pred_y, average='binary', pos_label='ugly')
    print("Precision: ", precision)

    recall = recall_score(actual_y, pred_y, average='binary', pos_label='ugly')
    print("Recall: ", recall)

    # Calculate F1-score
    f1 = f1_score(actual_y, pred_y, average='binary', pos_label='ugly')
    print("F1-Score: ", f1)

    fw = open(utility.BASE_PATH + "/leave_one_results.csv", "a")
    fw.write(test_project + "\t" + str(accuracy) + "\t"+ str(precision)+ "\t"+
             str(recall)+ "\t" + str(f1) + "\n")
    fw.close()

def train_model(algorithm, train_x, train_y):
    if algorithm == 'LogisticRegression':
        rf_cls = LogisticRegression(random_state=0, max_iter=10000, verbose=True)
    if algorithm == "RandomForest":
        rf_cls = RandomForestClassifier(n_estimators=10, max_depth=10, min_samples_split=5,
                                        min_samples_leaf=5, max_features=8)
    if algorithm == "DecisionTree":
        rf_cls = DecisionTreeClassifier(max_depth=7)

    if algorithm == "AdaBoost":
        rf_cls = AdaBoostClassifier(n_estimators=100, algorithm="SAMME", random_state=0)

    if algorithm == "SVM":
        rf_cls = make_pipeline(StandardScaler(),
                               SVC(max_iter=5000, C=0.1, kernel='rbf', degree=3, gamma='scale', coef0=0.1,
                                   shrinking=True, probability=False, tol=0.001, ))
    if algorithm == "NN":
        print("In NN")
        rf_cls = MLPClassifier(max_iter=1000, solver='adam', alpha=0, learning_rate_init=0.0001,
                               hidden_layer_sizes=(10), warm_start=False, verbose=True)
    rf_cls.fit(train_x, train_y)

    return rf_cls


def predict(X, cls):
    pred_Y = cls.predict(X)
    return pred_Y


def get_projects():
    SRC = "../../data/ML/all"
    projects = []
    for project in os.listdir(SRC):
        projects.append(project)
    return projects


def make_train_test(test_project):
    f_train = open(DEST_PATH + "train.csv", "w")
    f_test = open(DEST_PATH + "test.csv", "w")

    fr = open(SRC_PATH + 'checkstyle.csv')
    header = fr.readline()
    f_train.write(header.strip() + "\n")
    f_test.write(header.strip() + "\n")
    fr.close()

    for project in os.listdir(SRC_PATH):
        if project == test_project:
            fw = f_test
        else:
            fw = f_train
        fr = open(SRC_PATH + project)
        fr.readline()
        lines = fr.readlines()
        for line in lines:
            fw.write(line.strip() + "\n")
        fr.close()
    f_train.close()
    f_test.close()


if __name__ == "__main__":
    algorithms = ["LogisticRegression", "DecisionTree", "RandomForest", "AdaBoost", "SVM", "NN"]
    projects = get_projects()
    fw = open(utility.BASE_PATH + "/leave_one_results.csv", "w")
    fw.write("Project\tAccuracy\tPrecision\tRecall\tF1-Score\n")
    fw.close()
    algorithm = algorithms[1]
    for test_project in projects:
        make_train_test(test_project)

        train_file = "../../data/ML/train-test/train.csv"
        test_file = "../../data/ML/train-test/test.csv"
        train_data, test_data = load_data(train_file, test_file)

        train_x, train_y = clean_data(train_data)
        train_x, train_y = oversampling(train_x, train_y)

        test_x, test_y = clean_data(test_data)

        cls = train_model(algorithm, train_x, train_y)
        #print (cls.coef_[0])
        print("######################Test Project is: ", test_project, "##############")

        pred_y = predict(test_x, cls)
        report_results("Testing", algorithm, test_y, pred_y, test_project)
        print("############################")
